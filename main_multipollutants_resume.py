import os
import sys
import argparse
import pytorch_lightning as pl
from pytorch_lightning import loggers as pl_loggers
from src.config_manager import ConfigManager
from src.datamodule_fixed import AQNetDataModule
from src.model_multipollutants import MultiPollutantLightningModule


def main(config_path):
    print("ğŸš€ DÃ‰MARRAGE AQ_NET2 - PRÃ‰DICTION MULTI-POLLUANTS")
    
    # Initial setup
    cfg_mgr = ConfigManager(config_path)
    config = cfg_mgr.config
    
    print(f"ğŸ“‹ Configuration: {config_path}")
    print(f"ğŸ“Š RÃ©solution: {config['model']['img_size']}")
    print(f"ğŸ”§ Variables: {len(config['data']['variables'])}")
    print(f"ğŸ¯ Cibles: {config['data']['target_variables']} ({len(config['data']['target_variables'])} polluants)")
    print("ğŸ‡¨ğŸ‡³ MASQUE CHINE ACTIVÃ‰ dans la loss function")
    
    # Initialize Data Module
    print("ğŸ“ Initialisation du DataModule...")
    data_module = AQNetDataModule(config)
    
    # Initialize Model from scratch (no checkpoint for multi-pollutant yet)
    print("ğŸ§  Initialisation du modÃ¨le multi-polluants...")
    model = MultiPollutantLightningModule(config)
    print("âœ… ModÃ¨le multi-polluants initialisÃ©")
    
    # Loggers (TensorBoard + CSV)
    print("ğŸ“ˆ Configuration des loggers (TensorBoard + CSV)...")
    
    # TensorBoard Logger
    tb_logger = pl_loggers.TensorBoardLogger(
        save_dir="logs/",
        name="multipollutants_climax_ddp",
        log_graph=False
    )
    
    # CSV Logger
    csv_logger = pl_loggers.CSVLogger(
        save_dir="logs/",
        name="multipollutants_csv"
    )
    
    # Callbacks
    callbacks = [
        pl.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=config['callbacks']['early_stopping']['patience'],
            mode=config['callbacks']['early_stopping']['mode']
        ),
        pl.callbacks.ModelCheckpoint(
            monitor='val_loss',
            mode=config['callbacks']['model_checkpoint']['mode'],
            save_top_k=config['callbacks']['model_checkpoint']['save_top_k'],
            filename=config['callbacks']['model_checkpoint']['filename']
        )
    ]
    
    # Trainer
    trainer = pl.Trainer(
        num_nodes=4,
        devices=config['train']['devices'],
        accelerator=config['train']['accelerator'],
        strategy=config['train']['strategy'],
        precision=config['train']['precision'],
        max_epochs=config['train']['epochs'],
        logger=[tb_logger, csv_logger],
        callbacks=callbacks,
        gradient_clip_val=config['train']['gradient_clip_val'],
        accumulate_grad_batches=config['train']['accumulate_grad_batches'],
        log_every_n_steps=config['train']['log_every_n_steps'],
        val_check_interval=config['train']['val_check_interval'],
        default_root_dir=config['lightning']['trainer']['default_root_dir'],
        enable_checkpointing=config['lightning']['trainer']['enable_checkpointing'],
        enable_model_summary=config['lightning']['trainer']['enable_model_summary']
    )
    
    print("\n" + "="*60)
    print("ğŸƒâ€â™‚ï¸ DÃ‰MARRAGE DE L'ENTRAÃNEMENT MULTI-POLLUANTS")
    print("="*60)
    print(f"ğŸ¯ Polluants: {', '.join(config['data']['target_variables'])}")
    print(f"ğŸš€ Horizons: {config['data']['forecast_days']} jours")
    print(f"âš¡ GPUs: {config['train']['devices']}")
    print(f"ğŸ“¦ Batch size: {config['train']['batch_size']} par GPU")
    print("="*60 + "\n")
    
    # Start training
    trainer.fit(model, data_module)
    
    print("\nğŸ‰ ENTRAÃNEMENT TERMINÃ‰!")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="AQ_Net2 Multi-Pollutant Training")
    parser.add_argument("--config", type=str, default="configs/config_all_pollutants.yaml",
                        help="Path to config file")
    args = parser.parse_args()
    
    main(args.config)
