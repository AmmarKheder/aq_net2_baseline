#!/usr/bin/env python3
"""
ClimaX fine-tuning for PM2.5 - Train/Val/Test split + Metrics + Early Stopping
"""
import os
import argparse
from pathlib import Path
import time

# â”€â”€â”€ MIOpen cache fix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("ğŸ”§ Configuration systÃ¨me...")
os.environ["MIOPEN_CUSTOM_CACHE_DIR"] = "/scratch/project_462000640/ammar/miopen_cache"
os.environ["MIOPEN_USER_DB_PATH"]      = "/scratch/project_462000640/ammar/miopen_cache"
os.environ["MIOPEN_DISABLE_CACHE"]     = "0"
os.makedirs(os.environ["MIOPEN_CUSTOM_CACHE_DIR"], exist_ok=True)
os.environ["TIMM_FUSED_ATTN"] = "0"
print("âœ… Configuration MIOpen terminÃ©e")

print("ğŸ“¦ Chargement des modules...")
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import ReduceLROnPlateau
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

import sys
sys.path.insert(0, '/scratch/project_462000640/ammar/rossice/climax/src')
sys.path.insert(0, '/scratch/project_462000640/ammar/rossice/data')
from climax.arch import ClimaX
from caqra_dataloader import CAQRADataset
print("âœ… Modules chargÃ©s avec succÃ¨s")

# â”€â”€â”€ Model (head-only fine-tuning) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class PM25Model(nn.Module):
    def __init__(self, checkpoint_path, device='cuda'):
        super().__init__()
        print(f"ğŸ—ï¸  Initialisation du modÃ¨le PM25Model...")
        print(f"   ğŸ“ Device: {device}")
        print(f"   ğŸ“„ Checkpoint: {checkpoint_path}")
        
        # Variables mÃ©tÃ©o + pollution
        self.variables = ['u','v','temp','rh','psfc','pm10','so2','no2','co','o3']
        print(f"   ğŸŒ¡ï¸  Variables d'entrÃ©e: {self.variables}")
        
        # Backbone ClimaX
        print("   ğŸ§  Construction du backbone ClimaX...")
        self.climax = ClimaX(
            default_vars=self.variables,
            img_size=[128,256],
            patch_size=4,
            embed_dim=1024,
            depth=8, decoder_depth=2,
            num_heads=16, mlp_ratio=4,
            drop_path=0.1, drop_rate=0.1
        )
        print("   âœ… Backbone ClimaX crÃ©Ã©")
        
        # Charger les poids (sauf la head)
        print("   ğŸ“¥ Chargement des poids prÃ©-entraÃ®nÃ©s...")
        ckpt = torch.load(checkpoint_path, map_location='cpu')['state_dict']
        sd = {k[4:]:v for k,v in ckpt.items() if k.startswith('net.')}
        sd = {k:v for k,v in sd.items() if not k.startswith('head.')}
        self.climax.load_state_dict(sd, strict=False)
        print(f"   âœ… {len(sd)} poids chargÃ©s depuis le checkpoint")
        
        # Geler l'encoder
        frozen_params = 0
        for p in self.climax.parameters():
            p.requires_grad = False
            frozen_params += p.numel()
        print(f"   ğŸ§Š Encoder gelÃ© ({frozen_params:,} paramÃ¨tres)")
        
        # TÃªte de rÃ©gression PM2.5
        embed_dim = 1024
        self.head = nn.Sequential(
            nn.Conv2d(embed_dim, 256, 1),
            nn.GELU(),
            nn.Conv2d(256, 1, 1)
        )
        trainable_params = sum(p.numel() for p in self.head.parameters())
        print(f"   ğŸ¯ TÃªte de rÃ©gression crÃ©Ã©e ({trainable_params:,} paramÃ¨tres entraÃ®nables)")
        
        self.to(device)
        print("âœ… ModÃ¨le PM25Model initialisÃ© avec succÃ¨s")

    def forward(self, x):
        B,_,H,W = x.shape
        device = x.device
        lt = torch.zeros(B, device=device)
        feats = self.climax.forward_encoder(x, lt, self.variables)
        for blk in self.climax.blocks:
            feats = blk(feats)
        p = self.climax.patch_size
        h, w = H // p, W // p
        num = h * w
        feats = feats[:, :num]\
            .reshape(B, h, w, -1)\
            .permute(0, 3, 1, 2)
        if feats.shape[-2:] != (H, W):
            feats = nn.functional.interpolate(
                feats, size=(H, W), mode='bilinear', align_corners=False
            )
        return self.head(feats).squeeze(1)

# â”€â”€â”€ Ã‰valuation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def evaluate(model, loader, device):
    print("   ğŸ” Ã‰valuation en cours...")
    model.eval()
    all_pred, all_true = [], []
    eval_start = time.time()
    
    with torch.no_grad():
        for batch_idx, (X, y) in enumerate(loader):
            X = X[:, -1].to(device)
            y = y.squeeze(1).to(device)
            pred = model(X)
            all_pred.append(pred.cpu().numpy().ravel())
            all_true.append(y.cpu().numpy().ravel())
            
            if batch_idx % 20 == 0 and batch_idx > 0:
                print(f"      Batch {batch_idx}/{len(loader)} Ã©valuÃ©...")
    
    y_pred = np.concatenate(all_pred)
    y_true = np.concatenate(all_true)
    eval_time = time.time() - eval_start
    
    metrics = {
        'mae': mean_absolute_error(y_true, y_pred),
        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
        'r2':   r2_score(y_true, y_pred)
    }
    
    print(f"   âœ… Ã‰valuation terminÃ©e en {eval_time:.2f}s ({len(y_pred):,} prÃ©dictions)")
    return metrics

# â”€â”€â”€ Script principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main(args):
    print("ğŸš€ DÃ©marrage du fine-tuning ClimaX pour PM2.5")
    print("=" * 60)
    
    # Device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  Device utilisÃ©: {device}")
    if torch.cuda.is_available():
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   MÃ©moire GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

    # ModÃ¨le, optimiseur, scheduler, loss
    print("\nğŸ—ï¸  Construction du modÃ¨le...")
    model = PM25Model(args.checkpoint, device=device)
    
    print("\nâš™ï¸  Configuration de l'optimisation...")
    optimizer = torch.optim.Adam(model.head.parameters(), lr=args.lr)
    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)
    criterion = nn.MSELoss()
    print(f"   Optimiseur: Adam (lr={args.lr})")
    print(f"   Scheduler: ReduceLROnPlateau (factor=0.5, patience=3)")
    print(f"   Loss: MSE")

    # Jeu d'entraÃ®nement
    print(f"\nğŸ“š Chargement des donnÃ©es d'entraÃ®nement ({args.train_years})...")
    train_ds = CAQRADataset(
        data_path=args.data,
        years=args.train_years,
        variables=args.variables,
        target_variables=['pm25'],
        time_history=4,
        time_future=1,
        normalize=True
    )
    train_loader = DataLoader(train_ds, batch_size=args.bs, shuffle=True, num_workers=0)
    print(f"âœ… Dataset d'entraÃ®nement: {len(train_ds):,} Ã©chantillons, {len(train_loader)} batches")

    # Jeu de validation
    print(f"\nğŸ“– Chargement des donnÃ©es de validation ({args.val_years})...")
    val_ds = CAQRADataset(
        data_path=args.data,
        years=args.val_years,
        variables=args.variables,
        target_variables=['pm25'],
        time_history=4,
        time_future=1,
        normalize=True
    )
    val_loader = DataLoader(val_ds, batch_size=args.bs, shuffle=False, num_workers=0)
    print(f"âœ… Dataset de validation: {len(val_ds):,} Ã©chantillons, {len(val_loader)} batches")

    # Jeu de test
    print(f"\nğŸ“‹ Chargement des donnÃ©es de test ({args.test_years})...")
    test_ds = CAQRADataset(
        data_path=args.data,
        years=args.test_years,
        variables=args.variables,
        target_variables=['pm25'],
        time_history=4,
        time_future=1,
        normalize=True
    )
    test_loader = DataLoader(test_ds, batch_size=args.bs, shuffle=False, num_workers=0)
    print(f"âœ… Dataset de test: {len(test_ds):,} Ã©chantillons, {len(test_loader)} batches")

    # RÃ©sumÃ© des paramÃ¨tres
    print(f"\nğŸ“Š RÃ©sumÃ© de l'entraÃ®nement:")
    print(f"   Ã‰poques max: {args.epochs}")
    print(f"   Batch size: {args.bs}")
    print(f"   Early stopping patience: {args.patience}")
    print(f"   Variables: {len(args.variables)} ({', '.join(args.variables)})")

    print("\n" + "=" * 60)
    print("ğŸ¯ DÃ‰BUT DE L'ENTRAÃNEMENT")
    print("=" * 60)

    best_rmse, no_improve = float('inf'), 0
    total_train_time = 0

    for epoch in range(1, args.epochs + 1):
        epoch_start = time.time()
        print(f"\nğŸ“ˆ Ã‰poque {epoch}/{args.epochs}")
        print("-" * 40)
        
        # Phase entraÃ®nement
        print("ğŸ”¥ Phase d'entraÃ®nement...")
        model.train()
        train_loss = 0.0
        num_batches = 0
        
        for batch_idx, (X, y) in enumerate(train_loader):
            X = X[:, -1].to(device)
            y = y.squeeze(1).to(device)
            optimizer.zero_grad()
            loss = criterion(model(X), y)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            num_batches += 1
            
            if batch_idx % 50 == 0 and batch_idx > 0:
                print(f"   Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.6f}")

        avg_train_loss = train_loss / num_batches
        print(f"âœ… EntraÃ®nement terminÃ© - Loss moyenne: {avg_train_loss:.6f}")

        # Validation
        print("ğŸ” Phase de validation...")
        metrics = evaluate(model, val_loader, device)
        
        epoch_time = time.time() - epoch_start
        total_train_time += epoch_time
        
        print(f"ğŸ“Š RÃ©sultats Ã©poque {epoch}:")
        print(f"   Train Loss: {avg_train_loss:.6f}")
        print(f"   Val RMSE:   {metrics['rmse']:.4f}")
        print(f"   Val MAE:    {metrics['mae']:.4f}")
        print(f"   Val RÂ²:     {metrics['r2']:.4f}")
        print(f"   Temps:      {epoch_time:.1f}s")
        print(f"   LR actuel:  {optimizer.param_groups[0]['lr']:.2e}")

        # Scheduler & early stopping
        old_lr = optimizer.param_groups[0]['lr']
        scheduler.step(metrics['rmse'])
        new_lr = optimizer.param_groups[0]['lr']
        
        if new_lr < old_lr:
            print(f"ğŸ“‰ Learning rate rÃ©duit: {old_lr:.2e} â†’ {new_lr:.2e}")
        
        if metrics['rmse'] < best_rmse:
            best_rmse, no_improve = metrics['rmse'], 0
            torch.save(model.state_dict(), 'checkpoints/best_model.pt')
            print(f"ğŸ† Nouveau meilleur modÃ¨le sauvÃ©! RMSE: {best_rmse:.4f}")
        else:
            no_improve += 1
            print(f"â¸ï¸  Pas d'amÃ©lioration ({no_improve}/{args.patience})")
            
            if no_improve >= args.patience:
                print(f"\nâ±ï¸  Early stopping dÃ©clenchÃ© aprÃ¨s {epoch} Ã©poques")
                print(f"   Meilleur RMSE: {best_rmse:.4f}")
                break

    print("\n" + "=" * 60)
    print("ğŸ ENTRAÃNEMENT TERMINÃ‰")
    print("=" * 60)
    print(f"â±ï¸  Temps total d'entraÃ®nement: {total_train_time/60:.1f} minutes")
    print(f"ğŸ† Meilleur RMSE validation: {best_rmse:.4f}")

    # Test final
    print(f"\nğŸ§ª Ã‰valuation finale sur le jeu de test...")
    print("-" * 40)
    
    # Charger le meilleur modÃ¨le
    if os.path.exists('checkpoints/best_model.pt'):
        print("ğŸ“¥ Chargement du meilleur modÃ¨le...")
        model.load_state_dict(torch.load('checkpoints/best_model.pt'))
    
    test_metrics = evaluate(model, test_loader, device)
    
    print(f"\nğŸ¯ RÃ‰SULTATS FINAUX:")
    print("=" * 30)
    print(f"Test MAE:  {test_metrics['mae']:.4f}")
    print(f"Test RMSE: {test_metrics['rmse']:.4f}")
    print(f"Test RÂ²:   {test_metrics['r2']:.4f}")
    print("=" * 30)
    
    print(f"\nâœ… Fine-tuning terminÃ© avec succÃ¨s!")
    print(f"ğŸ’¾ ModÃ¨le sauvÃ© dans: checkpoints/best_model.pt")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--data',       type=str,   default="/scratch/project_462000640/ammar/data_rossice/")
    parser.add_argument('--checkpoint', type=str,   default="checkpoints/climax_1.40625deg.ckpt")
    parser.add_argument('--train_years',type=int,   nargs='+', default=[2013,2014,2015])
    parser.add_argument('--val_years',  type=int,   nargs='+', default=[2016,2017])
    parser.add_argument('--test_years', type=int,   nargs='+', default=[2018])
    parser.add_argument('--variables',  type=str,   nargs='+', default=['u','v','temp','rh','psfc','pm10','so2','no2','co','o3'])
    parser.add_argument('--bs',         type=int,   default=32)
    parser.add_argument('--epochs',     type=int,   default=8)
    parser.add_argument('--lr',         type=float, default=1e-4)
    parser.add_argument('--patience',   type=int,   default=5)
    args = parser.parse_args()

    Path("checkpoints").mkdir(exist_ok=True)
    main(args)